# Visual Search Task Using Natural Stimuli

We perform visual searches multiple times a day. Before leaving the house, for example, we might have to search for our keys. But how exactly do 
we know where to look? Research in the field of visual perception and search has mostly focused on understanding and examining unnatural, abstract 
tasks and simplistic stimuli such as lines and color patches. This research has helped tremendously in understanding the basic properties of perception, 
however, we perceive much more than just simple lines. The environment we act within and interact with is much more complex than that and us humans receive 
input from many different modalities that help us make sense of it, e.g. acoustic and visual input. Thus, research focusing solely on simplified  stimuli and 
the visual input during search does not suffice to explain human perception and behavior in its entirety.

Vision is generally considered to dominate the multisensory perception of the world. Shams and colleagues (2000) however have shown that auditory information can 
qualitatively alter the perception of a visual stimulus. Therefore, they showed that visual perception can be manipulated by other sensory modalities.

 
# This experiment  
I want to see whether hearing and seeing an item will improve visual search compared to seeing the item without sound/with the sound of another item. <p></p>

At each time, <i> N </i> = 12 pictures are presented at random locations within a circle on the display such that there is no overlap between the pictures. 
N will stay fixed throughout all trials. Participants are told an object and asked whether it is present in the following search display, having to indicate their answer via key-press/mouse (mouse to show were exactly the target object is?). During the search, a sound will be played that either corresponds to the target object or not. <p></p>


# Procedure
At the beginning of each trial, a fixation cross is presented for 500ms. Afterwards, the target cue is shown (e.g., "car") for a duration of 1500 ms, immediately followed by another fixation cross that is shown for another 300 ms. Lastly, the search display is presented in which the target is either present or not. At the same time, a sound will be played that is either
congruent or incongruent with the cued target object. <p></p>

Participants will have to do 15 practice trials first to get used to the task. Afterwards, the experiment begins and participants can start with the actual experiment.


# Hypothesis
Participants will exhibit faster reaction times in congruent trials (trials where sound and image match) compared to incongruent trials (trials where sound and image do not match) during the visual search task using natural stimuli, indicating that congruent multisensory information enhances visual search efficiency. Similarily, participants will report that the cued target object is not present when it is in fact not present faster, if the sound played does not match the cued target, as it reinforces the believe that the item really is not present in the search display. 


# Stimuli 
## Visual: 
Images of items

## Audio: 
Corresponding sound
- which database? 
